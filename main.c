/*******************************************************************************
* Copyright (C) 2019-2023 Maxim Integrated Products, Inc., All rights Reserved.
*
* This software is protected by copyright laws of the United States and
* of foreign countries. This material may also be protected by patent laws
* and technology transfer regulations of the United States and of foreign
* countries. This software is furnished under a license agreement and/or a
* nondisclosure agreement and may only be used or reproduced in accordance
* with the terms of those agreements. Dissemination of this information to
* any party or parties not specified in the license agreement and/or
* nondisclosure agreement is expressly prohibited.
*
* The above copyright notice and this permission notice shall be included
* in all copies or substantial portions of the Software.
*
* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
* OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
* MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
* IN NO EVENT SHALL MAXIM INTEGRATED BE LIABLE FOR ANY CLAIM, DAMAGES
* OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
* ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
* OTHER DEALINGS IN THE SOFTWARE.
*
* Except as contained in this notice, the name of Maxim Integrated
* Products, Inc. shall not be used except as stated in the Maxim Integrated
* Products, Inc. Branding Policy.
*
* The mere transfer of this software does not imply any licenses
* of trade secrets, proprietary technology, copyrights, patents,
* trademarks, maskwork rights, or any other form of intellectual
* property whatsoever. Maxim Integrated Products, Inc. retains all
* ownership rights.
*******************************************************************************/

// aslnet
// This file was @generated by /Users/eikehimstedt/Documents/FS23/MLonMCU/Exercise8/ai8x/ai8x-synthesis/ai8xize.py --test-dir synthed_net --prefix aslnet --checkpoint-file trained/aslnet_trained-q.pth.tar --config-file networks/aslnet.yaml --sample-input tests/sample_asl.npy --softmax --device MAX78000 --board-name FTHR_RevA --compact-data --mexpress --timer 0 --display-checkpoint --verbose --overwrite

#include <stdlib.h>
#include <stdint.h>
#include <string.h>
#include <stdio.h>
#include "mxc.h"
#include "cnn.h"
#include "camera.h"
#include "sample_ASL_R.h"
#include "sample_ASL_A.h"

volatile uint32_t cnn_time; // Stopwatch
//imported defines for the camera.
#define CAMERA_FREQ (8330000)


#define IMAGE_SIZE_X 64
#define IMAGE_SIZE_Y 64

#define CON_BAUD 115200 * 1


void fail(void)
{
  printf("\n*** FAIL ***\n\n");
  while (1);
}

// 3-channel 64x64 data input (12288 bytes total / 4096 bytes per channel):
// HWC 64x64, channels 0 to 0
static const uint32_t input_4[] = Sample_ASL_A_0;

// HWC 64x64, channels 1 to 1
static const uint32_t input_8[] = Sample_ASL_A_1;

// HWC 64x64, channels 2 to 2
static const uint32_t input_12[] = Sample_ASL_A_2;


void load_input(void)
{
  // This function loads the sample data input -- replace with actual data
 //copies the data from input_4/8/12 to the position where the neural network will read it.
	// so i need to find out where the camera stores the data and copy it from there(input_4 -> camera input) to the designated memory location.

  memcpy32((uint32_t *) 0x50408000, input_4, 4096);
  memcpy32((uint32_t *) 0x50410000, input_8, 4096);
  memcpy32((uint32_t *) 0x50418000, input_12, 4096);
}

/*
void load_input(void) {
    // Camera
    uint8_t *frame_buffer;
    uint8_t *buffer;
    uint32_t imgLen;
    uint32_t w, h, x, y;
    uint8_t r, g, b;
    uint32_t *input_4 = (uint32_t *)0x50408000;
    uint32_t *input_8 = (uint32_t *)0x50410000;
    uint32_t *input_12 = (uint32_t *)0x50418000;

    camera_start_capture_image();

    while (!camera_is_image_rcv()) {}

    camera_get_image(&frame_buffer, &imgLen, &w, &h);
    buffer = frame_buffer;

    printf("Width:%d Height:%d\n", w, h);

    for (y = 0; y < h; y++) {
        for (x = 0; x < w; x++) {
            r = *buffer++;
            g = *buffer++;
            b = *buffer++;
            buffer++; // skip msb=0x00

            // Store RGB values in separate memory locations
            *input_4++ = r;
            *input_8++ = g;
            *input_12++ = b;
        }
    }
}
*/


// Classification layer:
static int32_t ml_data[CNN_NUM_OUTPUTS];
static q15_t ml_softmax[CNN_NUM_OUTPUTS];

void softmax_layer(void)
{
  cnn_unload((uint32_t *) ml_data);
  softmax_q17p14_q15((const q31_t *) ml_data, CNN_NUM_OUTPUTS, ml_softmax);
}

int main(void)
{
	//turning on the camera and evalutating it, might need an import


#if defined(BOARD_FTHR_REVA)
    // Wait for PMIC 1.8V to become available, about 180ms after power up.
    MXC_Delay(200000);
    /* Enable camera power */
    Camera_Power(POWER_ON);
    printf("*******************\n Live Inference of Sign Letters \n Eike Himstedt \n*******************\n ");
    printf("Turned on the camera \n");
#endif


  MXC_ICC_Enable(MXC_ICC0); // Enable cache

  // Switch to 100 MHz clock
  MXC_SYS_Clock_Select(MXC_SYS_CLOCK_IPO);
  SystemCoreClockUpdate();

  printf("Waiting...\n");

  // DO NOT DELETE THIS LINE:
  MXC_Delay(SEC(3)); // Let debugger interrupt if needed


  // imported code for the camera implementation:
  //-------------------------------------------------------

  // Configure P2.5, turn on the CNN Boost
  mxc_gpio_cfg_t gpio_out;
  gpio_out.port = MXC_GPIO2;
  gpio_out.mask = MXC_GPIO_PIN_5;
  gpio_out.pad = MXC_GPIO_PAD_NONE;
  gpio_out.func = MXC_GPIO_FUNC_OUT;
  MXC_GPIO_Config(&gpio_out);
  MXC_GPIO_OutSet(gpio_out.port, gpio_out.mask);


  int xx = IMAGE_SIZE_X;
  int yy = IMAGE_SIZE_Y;
  char letters[] = "ABCDEFGHIJKLMNOPQRSTUVWXYZ";

  printf("x %d  y %d\n", xx, yy);


  int dma_channel;
  // Initialize camera.
  printf("Init Camera...");

  // Initialize DMA for camera interface
  MXC_DMA_Init();
  dma_channel = MXC_DMA_AcquireChannel();

  camera_init(CAMERA_FREQ);

  int ret = camera_setup(IMAGE_SIZE_X, IMAGE_SIZE_Y, PIXFORMAT_RGB565, FIFO_THREE_BYTE, USE_DMA,
                         dma_channel);

  if (ret != STATUS_OK) {
      printf("\tError returned from setting up camera. Error %d\n", ret);
      return -1;
  }


  // imported code end.
  //--------------------------------------------------


  // Enable peripheral, enable CNN interrupt, turn on CNN clock
  // CNN clock: APB (50 MHz) div 1
  cnn_enable(MXC_S_GCR_PCLKDIV_CNNCLKSEL_PCLK, MXC_S_GCR_PCLKDIV_CNNCLKDIV_DIV1);

  printf("\n*** CNN Inference Test aslnet_live ***\n");

  cnn_init(); // Bring state machine into consistent state
  cnn_load_weights(); // Load kernels
  printf("Classification results:\n");

  while (1){
	  cnn_init();
	  cnn_load_bias();
	  cnn_configure(); // Configure state machine
	  load_input(); // Load data input
	  cnn_start(); // Start CNN processing

	  while (cnn_time == 0)
		MXC_LP_EnterSleepMode(); // Wait for CNN


	  softmax_layer();

	  printf("\n*** PASS ***\n");

	#ifdef CNN_INFERENCE_TIMER
	  printf("Approximate inference time: %u us\n", cnn_time);
	  printf("i.e. %u clock cycles\n\n", cnn_time*200);
	#endif

	  //cnn_disable(); // Shut down CNN clock, disable peripheral

	  int i;
	  int digs, tens;
	  int highest_class=0;
	  for (i = 0; i < CNN_NUM_OUTPUTS; i++) {
		if (ml_softmax[i]>ml_softmax[highest_class]){
			highest_class = i;
		}
	  }
	digs = (1000 * ml_softmax[highest_class] + 0x4000) >> 15;
	tens = digs % 10;
	digs = digs / 10;

	if(highest_class<26){
		printf("[%7d] -> Class %c: %d.%d%%\n", ml_data[highest_class], letters[highest_class], digs, tens);
	};
    MXC_Delay(SEC(2));

  }
  return 0;
}
